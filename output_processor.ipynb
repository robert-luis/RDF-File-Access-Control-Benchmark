{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configurable\n",
    "# Number of max and mins to drop\n",
    "n_drop = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as read_file:\n",
    "    conf = json.load(read_file)\n",
    "    \n",
    "data = conf['data']\n",
    "queries = conf['queries']\n",
    "runs = conf['runs']\n",
    "\n",
    "queryDirs = []\n",
    "#Calling function to greate data sets\n",
    "for task in data:\n",
    "    path = './src/output/'\n",
    "    for subT in data[task]:\n",
    "        path_subT = path + task + '/' + subT + '/'\n",
    "        for q in queries:\n",
    "            queryDirs.append(path_subT + q + '/')\n",
    "\n",
    "conf['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General functions\n",
    "\n",
    "# Dropping n * (min and max) from runtimes\n",
    "def dropMinAndMax(n_drop, timeList):\n",
    "    for i in range(n_drop):\n",
    "        if timeList.size > 3:\n",
    "            timeList = timeList.reset_index(drop=True)\n",
    "            timeList = timeList.drop(timeList.values.argmax())\n",
    "            timeList = timeList.reset_index(drop=True)\n",
    "            timeList = timeList.drop(timeList.values.argmin())\n",
    "        return timeList\n",
    "\n",
    "# Function for saving figures\n",
    "def saveFig(label):\n",
    "    result_path = './results/'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    plt.savefig(result_path + label + '_plot.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating general dataframe with all results and experimental details\n",
    "\n",
    "dfResult = pd.DataFrame(columns = ['task', 'subT', 'queryNr', 'run', 'time', 'result', 'pods', 'posts', 'auths', 'acEnforce'])\n",
    "c = 0\n",
    "error_count = 0\n",
    "error_list = []\n",
    "# Reading in of output files\n",
    "for directory in queryDirs:  \n",
    "\n",
    "    for r in range(runs):\n",
    "        run = 'run' + str(r + 1) + '.json'\n",
    "        path = directory + run\n",
    "        if os.path.isfile(path):\n",
    "            with open(path, 'r') as f:  \n",
    "                file = json.load(f)\n",
    "                # Retrieving result data from output file\n",
    "                for columns in ['task', 'subT', 'queryNr', 'run', 'time', 'result']:\n",
    "                    dfResult.at[c, columns] = file[columns]\n",
    "                # Retrieving experimentdata from configuration file\n",
    "                for columns in ['pods', 'posts', 'auths', 'acEnforce']:\n",
    "                    dfResult.at[c, columns] = data[file['task']][file['subT']][columns]\n",
    "                c += 1\n",
    "        else:\n",
    "            error_count += 1\n",
    "            error_list.append(path)\n",
    "\n",
    "# Converting Miliseconds to seconds\n",
    "dfResult['time'] = dfResult['time'].apply(lambda x: x/1000)\n",
    "\n",
    "# Calculation of aQET and aQMET\n",
    "for task in data:\n",
    "    for subT in data[task]:\n",
    "        for q in queries:\n",
    "            # calculate query execution time for each query\n",
    "            timeList = dfResult[(dfResult.subT == subT) & (dfResult.queryNr == q)].time\n",
    "            timeList = dropMinAndMax(n_drop, timeList)\n",
    "            aQET = round(timeList.mean(),3)\n",
    "            dfResult.loc[dfResult[(dfResult.subT == subT) & (dfResult.queryNr == q)].index, 'aQET'] = aQET\n",
    "\n",
    "        # calculate average query execution time over all queries\n",
    "        timeList = dfResult[(dfResult.subT == subT)].aQET\n",
    "        timeList = dropMinAndMax(n_drop, timeList)\n",
    "        aQMET = round(timeList.mean(),3)\n",
    "        dfResult.loc[dfResult[(dfResult.subT == subT)].index, 'aQMET'] = aQMET\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Saving Dataframe including all data\n",
    "dfResult.to_csv('./results/results_table.csv')\n",
    "\n",
    "# Print the runs the failed and the total amount\n",
    "total_runs = error_count + c \n",
    "print('Number or failed runs: ', error_count, ' of ', total_runs)\n",
    "print('Paths with error: ')\n",
    "for error in error_list:\n",
    "    print('  -', error)\n",
    "\n",
    "dfResult.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalised plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfResult = pd.read_csv('./other/results/results5/results_table.csv')\n",
    "dfQueries = dfResult.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# aQMET dataframe\n",
    "dfResult = dfResult[['task', 'subT', 'aQMET', 'pods', 'posts', 'auths', 'acEnforce']] #, 'aQET', 'queryNr'\n",
    "dfResult = dfResult.drop_duplicates()\n",
    "dfResult = dfResult.reset_index(drop = True)\n",
    "dfResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aQET daraframe\n",
    "dfQueries = dfQueries[['task', 'subT', 'pods', 'posts', 'auths', 'acEnforce', 'aQET', 'queryNr']] #different queries graph\n",
    "\n",
    "# t# & q1\n",
    "dfQueries = dfQueries[(dfQueries.queryNr == 'q1')]\n",
    "dfQueries = dfQueries.drop_duplicates()\n",
    "dfQueries = dfQueries.reset_index(drop = True)\n",
    "dfQueries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "def drawComparisonPlot(t1, t2, df, xaxis, timeMeasure, xlabel):\n",
    "    AccEnforced = df[(df.task == t1)][timeMeasure]\n",
    "    AccNotEnforced = df[(df.task == t2)][timeMeasure]\n",
    "    \n",
    "    if t1 =='t5':\n",
    "        x = pd.Series([33, 66, 100])\n",
    "        plt.plot(x,AccEnforced, 'bo-', label = 'Access Enforced')\n",
    "        plt.plot(x,AccNotEnforced, 'r+-', label = 'Access Not Enforced')\n",
    "    else:\n",
    "        #x = df[(df.task == t1)][xaxis]\n",
    "        x = pd.Series([2, 4, 8, 16, 32])\n",
    "        \n",
    "        plt.semilogx(x,AccEnforced, 'bo-', label = 'Access Enforced', basex=2)\n",
    "        plt.semilogx(x,AccNotEnforced, 'r+-', label = 'Access Not Enforced', basex=2)\n",
    "        \n",
    "        #Logarithmic y scale\n",
    "        #plt.loglog(x,AccEnforced, 'bo-',label = 'Access Enforced', basex=2, basey=2)\n",
    "        #plt.loglog(x,AccNotEnforced, 'r+-', label = 'Access not Enforced', basex=2, basey=2)\n",
    "        \n",
    "        plt.xticks([2, 4, 8, 16, 32], ['2', '4', '8', '16', '32'])\n",
    "        #plt.yticks([0.01, 0.9, 1, 1.1, 1.2, 1.3, 2], ['0', '0.9', '1', '1.1', '1.2', '1.3', '2'])\n",
    "        \n",
    "    plt.ylim(bottom=0, top=1.5)\n",
    "#    plt.ylim(bottom=0, top=1400)\n",
    "#    plt.ylim(bottom=2, top=2**12)\n",
    "    \n",
    "    #plt.xlabel(xaxis.capitalize())\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(str(timeMeasure) + ' in s')\n",
    "    #plt.title(str(timeMeasure) + ' for Increse in ' + xaxis.capitalize())\n",
    "    plt.legend(loc='best')\n",
    "    plt.rcParams[\"font.size\"] = \"15\"\n",
    "\n",
    "    plt.tight_layout()\n",
    "    saveFig(str(xaxis))\n",
    "   \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawOverheadPlot(t1, t2, df, xaxis, timeMeasure, xlabel):\n",
    "    AccEnforced = df[(df.task == t1)][timeMeasure]\n",
    "    AccNotEnforced = df[(df.task == t2)][timeMeasure]\n",
    "    overhead = AccEnforced.divide(AccNotEnforced.values)\n",
    "    overhead = overhead.sub(1)\n",
    "    overhead = overhead.mul(100)\n",
    "    \n",
    "    if t1 =='t5':\n",
    "        x = pd.Series([33, 66, 100])\n",
    "        plt.plot(x, overhead, 'g')\n",
    "    else:\n",
    "        #x = df[(df.task == t1)][xaxis]\n",
    "        x = pd.Series([2, 4, 8, 16, 32])\n",
    "        plt.semilogx(x, overhead, 'g', basex=2)\n",
    "        plt.xticks([2, 4, 8, 16, 32], ['2', '4', '8', '16', '32'])\n",
    "    \n",
    "    plt.ylim(bottom=0, top=100)\n",
    "    \n",
    "    #plt.xlabel(xaxis.capitalize())\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(str(timeMeasure) + ' Overhead (%)')\n",
    "    #plt.title(str(timeMeasure) + ' Overhead for Increse in ' + xaxis.capitalize())\n",
    "    #plt.legend(loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    saveFig('overhead_' + str(xaxis))\n",
    "       \n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dfResult[dfResult.task == 't2'].shape[0] > 0:\n",
    "    drawComparisonPlot('t1', 't2', dfResult, 'pods', 'aQMET', 'Number of Pods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dfResult[dfResult.task == 't2'].shape[0] > 0:\n",
    "    drawOverheadPlot('t1', 't2', dfResult, 'pods', 'aQMET', 'Number of Pods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dfResult[dfResult.task == 't4'].shape[0] > 0:\n",
    "    drawComparisonPlot('t3', 't4', dfResult ,'posts', 'aQMET', 'Number of Posts per Pod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dfResult[dfResult.task == 't4'].shape[0] > 0:\n",
    "    drawOverheadPlot('t3', 't4', dfResult ,'posts', 'aQMET', 'Number of Posts per Pod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dfResult[dfResult.task == 't6'].shape[0] > 0:\n",
    "    drawComparisonPlot('t5', 't6', dfQueries, 'auth', 'aQET', '% of Profile authorised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dfResult[dfResult.task == 't6'].shape[0] > 0:\n",
    "    drawOverheadPlot('t5', 't6', dfQueries, 'auth', 'aQET', '% of Profile authorised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
