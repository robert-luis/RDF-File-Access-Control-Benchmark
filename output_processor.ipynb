{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint # Delete\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of max and mins to drop\n",
    "n_drop = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as read_file:\n",
    "    conf = json.load(read_file)\n",
    "    pprint(conf['data'])\n",
    "    \n",
    "data = conf['data']\n",
    "queries = conf['queries']\n",
    "runs = conf['runs']\n",
    "queryDirs = []\n",
    "#Calling function to greate data sets\n",
    "for task in data:\n",
    "    path = './src/output/'\n",
    "    for subT in data[task]:\n",
    "        path_subT = path + task + '/' + subT + '/'\n",
    "        for q in queries:\n",
    "            queryDirs.append(path_subT + q + '/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General functions\n",
    "\n",
    "# Dropping n * (min and max) from runtimes\n",
    "def dropMinAndMax(n_drop, timeList):\n",
    "    for i in range(n_drop):\n",
    "        timeList = timeList.reset_index(drop=True)\n",
    "        timeList = timeList.drop(timeList.values.argmax())\n",
    "        timeList = timeList.reset_index(drop=True)\n",
    "        timeList = timeList.drop(timeList.values.argmin())\n",
    "    return timeList\n",
    "\n",
    "# Function for saving figures\n",
    "def saveFig(label):\n",
    "    path = './results/'\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError:\n",
    "        print ('Directory: ' + str(path) + ' already exists')\n",
    "    else: \n",
    "        pass\n",
    "    plt.savefig('./results/' + label + '_plot.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating general dataframe with all results and experimental details\n",
    "\n",
    "dfResult = pd.DataFrame(columns = ['task', 'subT', 'queryNr', 'run', 'time', 'result', 'pods', 'posts', 'auths', 'acEnforce'])\n",
    "c = 0\n",
    "# Reading in of output files\n",
    "for directory in queryDirs:  \n",
    "\n",
    "    for r in range(runs):\n",
    "        run = 'run' + str(r + 1) + '.json'\n",
    "        path = directory + run\n",
    "        with open(path, 'r') as f:  \n",
    "            file = json.load(f)\n",
    "            # Retrieving result data from output file\n",
    "            for columns in ['task', 'subT', 'queryNr', 'run', 'time', 'result']:\n",
    "                dfResult.at[c, columns] = file[columns]\n",
    "            # Retrieving experimentdata from configuration file\n",
    "            for columns in ['pods', 'posts', 'auths', 'acEnforce']:\n",
    "                dfResult.at[c, columns] = data[file['task']][file['subT']][columns]\n",
    "                \n",
    "            c += 1\n",
    "\n",
    "# Calculation of QET and aQEToA\n",
    "for task in data:\n",
    "    for subT in data[task]:\n",
    "        for q in queries:\n",
    "            # calculate query execution time for each query\n",
    "            timeList = dfResult[(dfResult.subT == subT) & (dfResult.queryNr == q)].time\n",
    "            timeList = dropMinAndMax(n_drop, timeList)\n",
    "            QET = round(timeList.mean(),0)\n",
    "            dfResult.loc[dfResult[(dfResult.subT == subT) & (dfResult.queryNr == q)].index, 'QET'] = QET\n",
    "\n",
    "        # calculate average query execution time over all queries\n",
    "        timeList = dfResult[(dfResult.subT == subT)].QET\n",
    "        timeList = dropMinAndMax(n_drop, timeList)\n",
    "        aQEToA = round(timeList.mean(),0)\n",
    "        dfResult.loc[dfResult[(dfResult.subT == subT)].index, 'aQEToA'] = aQEToA\n",
    "\n",
    "# Dataframe including all data\n",
    "dfResult.to_csv('./results/results_table.csv')\n",
    "dfResult.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalised plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aQEToA dataframe\n",
    "dfResult = dfResult[['task', 'subT', 'aQEToA', 'pods', 'posts', 'auths', 'acEnforce']] #, 'QET', 'queryNr'\n",
    "dfResult = dfResult.drop_duplicates()\n",
    "dfResult = dfResult.reset_index(drop = True)\n",
    "dfResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawOverheadPlot(t1, t2, xlabel):\n",
    "    AccEnforced = dfResult[(dfResult.task == t1)].aQEToA\n",
    "    AccNotEnforced = dfResult[(dfResult.task == t2)].aQEToA\n",
    "    #x = dfResult[(dfResult.task == task)][xlabel]\n",
    "    x = dfResult[(dfResult.task == t1)][xlabel]\n",
    "    \n",
    "    plt.plot(x,AccEnforced, label = 'AccEnforced')\n",
    "    plt.plot(x,AccNotEnforced, label = 'AccNotEnforced')\n",
    "    plt.ylim(bottom=0)\n",
    "    \n",
    "    plt.xlabel(xlabel.capitalize())\n",
    "    plt.ylabel('aQEToA in ms')\n",
    "    plt.title('Average Query Execution Time over all Queries for Increse in ' + xlabel.capitalize())\n",
    "    plt.legend(loc='best')\n",
    "    saveFig(xlabel)\n",
    "   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawOverheadPlot('t1', 't2', 'pods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawOverheadPlot('t3', 't4', 'posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawAuthPlot(task, xlabel):\n",
    "    y = dfResult[(dfResult.task == task)].aQEToA\n",
    "\n",
    "    #x = dfResult[(dfResult.task == task)][xlabel]\n",
    "    x = (0.33, 0.66, 1)\n",
    "    \n",
    "    plt.plot(x,y)\n",
    "    plt.ylim(bottom=0)\n",
    "    \n",
    "    plt.xlabel('% of Profile authorised')\n",
    "    plt.ylabel('aQEToA in ms')\n",
    "    plt.title('Average Query Execution Time over all Queries for Increse in Authorisations')\n",
    "    \n",
    "    saveFig(xlabel)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawAuthPlot('t5', 'auths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
